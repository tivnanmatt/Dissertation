%
% Simple template for generating drafts of papers and articles
%
\documentclass[12pt,]{article}
\usepackage{authblk}
\usepackage{fullpage}
\usepackage{amssymb,amsmath}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{siunitx}
\usepackage[version=3]{mhchem}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}

% \usepackage{natbib}
% \bibliographystyle{ametsoc2014}

\usepackage[left]{lineno}
% \linenumbers

\newcommand{\indep}{\perp \!\!\! \perp}

\usepackage{setspace}
% \doublespacing

% \usepackage[unicode=true]{hyperref}
% \hypersetup{breaklinks=true,
%             colorlinks=false,
%             pdfborder={0 0 0}}
% \urlstyle{same} % don't use a different (monospace) font for urls

% \setcounter{secnumdepth}{5}

% \usepackage{graphicx}
% \graphicspath{{figures/}}
% % Redefine \includegraphics so that, unless explicit options are
% % given, the image width will not exceed the width or the height of the page.
% % Images get their normal width if they fit onto the page, but
% % are scaled down if they would overflow the margins.
% \makeatletter
% \def\ScaleWidthIfNeeded{%
%  \ifdim\Gin@nat@width>\linewidth
%     \linewidth
%   \else
%     \Gin@nat@width
%   \fi
% }
% \def\ScaleHeightIfNeeded{%
%   \ifdim\Gin@nat@height>0.9\textheight
%     0.9\textheight
%   \else
%     \Gin@nat@width
%   \fi
% }
% \makeatother
% \setkeys{Gin}{width=\ScaleWidthIfNeeded,height=\ScaleHeightIfNeeded,keepaspectratio}%

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Fourier Diffusion Models: A Method to Control MTF and NPS in Score-Based Stochastic Image Generation}
\author[1]{\small Matthew Tivnan}
\author[1]{Jacopo Teneggi}
\author[2]{Tzu-Cheng Lee}
\author[2]{Ruoqiao Zhang}
\author[3]{Kirsten Boedeker}
\author[2]{\\Liang Cai}
\author[4]{Grace J. Gang}
\author[1]{Jeremias Sulam}
\author[1]{J. Webster Stayman}

\affil[1]{\scriptsize Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA}
\affil[2]{Canon Medical Research, USA. Vernon Hills, IL, USA}
\affil[3]{Canon Medical Systems Corporation, Otawara, Japan}
\affil[4]{Department of Radiology, Hospital of the University of Pennsylvania, Philadelphia, PA, USA}
\date{\small \today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

% \newpage

\begin{abstract}
    Score-based diffusion models have recently been demonstrated as powerful machine learning based tools for conditional and unconditional image generation. Typically, these models are based on a forward stochastic process where noise is gradually added and there can also be deterministic drift, where the original image signal is scaled to zero over time. A neural network is then trained to approximate the time-dependent score function, or the gradient of the logarithm of the probability density function. Using this score estimator, it is possible to run an approximation of the reverse-time stochastic process to sample new images from the training distribution. These score-based generative models have been shown to outperform generative adversarial neural networks using standard benchmarks and metrics. However, one issue with this approach is that it requires a large number of forward passes of the neural network. Additionally, the images at intermediate time steps are not directly useful, since the signal-to-noise ratio is low. In this work we present a new method called Fourier Diffusion Models which replaces the scalar operations of the forward process with shift-invariant convolutions and the additive white noise with the more general case of additive noise that is spatially stationary. This allows for control of modulation transfer function (MTF) and noise power spectrum (NPS) at intermediate time steps. Additionally, we show that the forward process can be crafted to converge to the same MTF and NPS as the measured images. In this way, we can model continuous probability flow from true images to measured images. We compare Fourier diffusion models to existing scalar diffusion models and show that they achieve a higher level of performance and allow for a smaller number of time steps. 
\end{abstract}


\newpage
\section{Introduction}

Denoising diffusion probabilistic models \cite{sohl2015deep, ho2020denoising} and closely-related score-based generative models through stochastic differential equations \cite{song2020score} have recently been demonstrated as powerful machine learning based tools for conditional and unconditional image generation. These diffusion models are based on a stochastic process in which the true images are degraded over time through additive white noise and, in some cases, a deterministic scaling down of the signal to zero. Then, a neural network can be trained to estimate the time-dependent score function which allows one to run the reverse-time stochastic process starting with a known prior distribution (pure noise in many cases), iteratively running reverse-time update steps, and eventually ending on an approximate sample from the same distribution as the training images. Compared to another popular method, generative adversarial neural networks, diffusion models can achieve higher image quality as measured with standard benchmarks while avoiding the difficulties of adversarial training \cite{dhariwal2021diffusion}. 


In this article, we present a new method called \emph{Fourier Diffusion Models,} which allow for  control of the modulation transfer function (MTF) and noise power spectrum (NPS) at each time step of the forward and reverse stochastic process. Our approach is to model the forward process as a cascade of linear shift-invariant (LSI) systems with additive stationary Gaussian noise (ASGN). Then, we train a neural network to approximate the time-dependent score function for iterative sharpening and denoising of the images to generate high-quality posterior samples given measured images with spatial blur and stationary correlated noise. One new feature of Fourier diffusion models compared to conventional scalar diffusion models is the capability to model continuous probability flow from ground truth images to measured images with a certain MTF and NPS. The initial results presented in this work show that Fourier diffusion models require fewer time steps for conditional image generation relative to scalar diffusion models. We believe this improvement is due to the fact that the true images are more similar to measured images than they are to pure white noise used to initialize the reverse process for most scalar diffusion models.

In the sections to follow, we provide detailed mathematical descriptions of Fourier diffusion models including the forward stochastic process, the training loss function for score-matching neural networks, and instructions on how to sample the reverse process for conditional or unconditional image generation. Finally, we present experimental methods and results for image restoration of low-radiation-dose CT measurements to demonstrate one practical application of the proposed method.








\section{Methods}

\subsection{Linear Shift-Invariant Systems with Stationary Gaussian Noise}

In this section, we describe the theoretical background for LSI systems with ASGN. This is a standard mathematical model used to evaluate the spatial resolution and noise covariance of medical imaging systems in the spatial frequency domain.

% While this approximation may not be exact for physical systems, it is a useful approximation and often used as a standard for image quality evaluation.  

% \subsubsection{Linear Shift-Invariant Systems}

A two-dimensional LSI system is mathematically defined by convolution with the impulse response function, also known as the point spread function (PSF), of the system. Fourier convolution theorem states that it is equivalent to multiply the two-dimensional Fourier transform of the input by the Fourier transform of the PSF, referred to as the modulation transfer function (MTF) of the system, followed by the inverse Fourier transform to produce the convolved output. For discrete systems, the voxelized values of a medical image can be represented as a flattened column vector and the convolution operation can be represented by a circulant matrix operator, $\mathbf{H} = \mathbf{U}^*_\text{DFT} \boldsymbol{\Lambda}_\text{MTF} \mathbf{U}_\text{DFT}$, where $\mathbf{U}_\text{DFT}$ is the unitary discrete two-dimensional Fourier transform, $\mathbf{U}^*_\text{DFT}$ is the unitary discrete two-dimensional inverse Fourier transform, and  $\boldsymbol{\Lambda}_\text{MTF}$ is a diagonal matrix representing element-wise multiplication by the MTF in the spatial frequency domain. 

% \subsubsection{LSI Systems with Additive Stationary Gaussian Noise}

If we assume the noise covariance between two voxels in an image does not depend on position, only on relative displacement between two positions, then we say the noise is spatially stationary, and the covariance can be fully defined by the noise power spectrum (NPS) in the spatial frequency domain. For the discrete case, stationary noise can be modeled by a circulant covariance matrix, $\boldsymbol{\Sigma} = \mathbf{U}^*_\text{DFT} \boldsymbol{\Lambda}_\text{NPS} \mathbf{U}_\text{DFT}$, where $\boldsymbol{\Lambda}_\text{NPS}$ is a diagonal matrix of spatial-frequency-dependent noise power spectral densities. In probabilistic terms, the output of an LSI system with ASGN is a multivariate Gaussian conditional probability density function parameterized by the MTF and NPS as follows:

\begin{equation}
    p(\mathbf{x}_\text{out}|\mathbf{x}_\text{in}) =  \mathcal{N}(\mathbf{x}_\text{out};  \mathbf{H} \hspace{1mm} \mathbf{x}_\text{in}, \boldsymbol{\Sigma} ).
\end{equation}

\noindent where $\mathbf{x}_\text{in}$ is the ground truth image and $\mathbf{x}_\text{out}$ is the degraded image. The notation, $\mathcal{N}(\mathbf{v};\boldsymbol{\mu}_\mathbf{v},\boldsymbol{\Sigma}_\mathbf{v})$ represents a multivariate Gaussian probability density function with argument, $\mathbf{v}$, parameterized by the mean vector $\boldsymbol{\mu}_\mathbf{v}$ and covariance matrix $\boldsymbol{\Sigma}_\mathbf{v}$.    
% This model describes spatial resolution and noise covariance in the spatial frequency domain. This is particularly useful for evaluating the detectability of image features of a certain size.

% \subsubsection{MTF and NPS in Cascaded LSI Systems}

% In some cases it is useful to consider a sequence or cascade of operations where each stage consists of one LSI system, $\mathbf{H}^{(n)}$ and additive Gaussian stationary noise with NPS, . We can show that  


\subsection{Discrete-Time Stochastic Process with MTF and NPS Control}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/ddpm_cartoon.png}
    \caption{A probabilistic graphical model for the stochastic process, consisting of linear shift invariant systems and additive stationary Gaussian noise. The  measurement-conditioned diffusion model, in light purple, is trained to approximate the reverse process, in dark purple.}
    \label{fig:network_diagram}
\end{figure}

% \subsubsection{Discrete-Time Forward Process: Cascaded LSI Systems with ASGN}

Consider a sequence of LSI systems with ASGN resulting in a discrete-time forward stochastic process as shown in Figure \ref{fig:network_diagram}. The update rule for a forward time step is defined as

\begin{equation}
    \mathbf{x}^{[n+1]} = \mathbf{H}_\Delta^{[n]} \mathbf{x}^{[n]} + {\boldsymbol{\Sigma}_\Delta^{[n]}}^{ \hspace{0mm}1/2}\boldsymbol{\eta}^{[n]}  .
    \label{eq:discrete_forward_update}
\end{equation} 

\noindent where $\mathbf{H}_\Delta^{[n]}$ is a circulant matrix representing an LSI system, $\boldsymbol{\Sigma}_\Delta$ is a circulant matrix representing the noise covariance of the ASGN,  and $\boldsymbol{\eta}^{[n]}$  is zero-mean identity-covariance Gaussian noise. Also, we assume the noise at a given time step is independent of the noise at all other time steps; that is, $\boldsymbol{\eta}^{[n]} \indep \boldsymbol{\eta}^{[m]} \hspace{1mm} \forall \hspace{1mm} n \neq m$. Stated differently, the conditional probability density function for a forward step is

\begin{equation}
    \text{p}(\mathbf{x}^{[n+1]}|\mathbf{x}^{[n]}) = \mathcal{N}(\mathbf{x}^{[n+1]} ; \mathbf{H}_\Delta^{[n]} \hspace{1mm} \mathbf{x}^{[n]},  \boldsymbol{\Sigma}_\Delta) .
    \label{eq:forward_step}
\end{equation}


Figure \ref{fig:network_diagram} shows that the full process can be represented by a directed acyclic probabilistic graphical model, which means the random vector at a given time step, $\mathbf{x}^{[n]}$, is defined as conditionally independent of random vectors at earlier time steps given the previous image, $\mathbf{x}^{[n-1]}$. Therefore, the joint distribution of the full forward process can be written as

\begin{equation}
\text{p}(\mathbf{x}^{[0]}, \mathbf{x}^{[1]},\mathbf{x}^{[2]},\ldots,\mathbf{x}^{[N]}) = \text{p}(\mathbf{x}^{[0]})\text{p}(\mathbf{x}^{[1]}| \mathbf{x}^{[0]})\text{p}(\mathbf{x}^{[2]}| \mathbf{x}^{[1]})\ldots\text{p}(\mathbf{x}^{[N]}| \mathbf{x}^{[N-1]}) \enspace ,
\end{equation}


\noindent where $N$ is the last time step. 

One example of this stochastic process would be the case where $\mathbf{H}_\Delta^{[n]}$ is convolutional blur and ${\boldsymbol{\Sigma}_\Delta^{[n]}}$ is correlated stationary noise. In that case, the image will become more blurry and noisy as time passes in the forward process. Then, as we will describe in a later section, a neural network can be trained to run the reverse-time stochastic process, which should result in a series of sharpening and noise-reducing steps to restore image quality.

% \subsubsection{Prescriptive Control of MTF and NPS in the Forward Process}

The cascade of LSI systems with ASGN leading up to a certain time point, $n$, can be described by an equivalent LSI system, $\mathbf{H}^{[n]} =  \mathbf{U}^*_\text{DFT} \boldsymbol{\Lambda}_{\text{MTF}}^{[n]} \mathbf{U}_\text{DFT}$, and ASGN with covariance, $\boldsymbol{\Sigma^{[n]}}=\mathbf{U}^*_\text{DFT}\boldsymbol{\Lambda}_{\text{NPS}}^{[n]}\mathbf{U}_\text{DFT}$, applied to the original image, $\mathbf{x^{[0]}}$ as shown below:

\begin{gather}
    \mathbf{x}^{[n]} = \mathbf{H}^{[n]} \mathbf{x}^{[0]} + {\boldsymbol{\Sigma}^{[n]}}^{ \hspace{0mm} 1/2} \boldsymbol{\epsilon}^{[n]}\\
    \text{p}(\mathbf{x}^{[n]}|\mathbf{x}^{[0]}) = \mathcal{N}(\mathbf{x}^{[n]} ;   \mathbf{H}^{[n]} \hspace{1mm} \mathbf{x}^{[0]},  \boldsymbol{\Sigma^{[n]}} ) .
    \label{eq:effective_MTF_NPS}
\end{gather}

\noindent where $\boldsymbol{\epsilon}^{[n]}$ is identity-covariance zero-mean Gaussian random process defined such that non-overlapping time intervals are independent. Our goal is to prescribe the effective MTF and NPS at every time step, and then define the forward process parameters accordingly. To that end, we can combine \eqref{eq:forward_step} and \eqref{eq:effective_MTF_NPS} to define $\mathbf{H}_\Delta^{[n]}$ as the inverse MTF for the current time step matrix multiplied by the MTF for the next time step as follows

\begin{gather}
    \mathbf{H}_\Delta^{[n]}  = \mathbf{H}^{[n+1]} {\mathbf{H}^{[n]}}^{-1} = \mathbf{U}^*_\text{DFT} \boldsymbol{\Lambda}_{\text{MTF}}^{[n+1]} {\boldsymbol{\Lambda}_{\text{MTF}}^{[n]}}^{\hspace{-3mm}-1} \mathbf{U}_\text{DFT} . \label{eq:LSI_in_terms_of_MTF_}
\end{gather}

\noindent When this LSI system, $\mathbf{H}_\Delta^{[n]}$, is applied to the Gaussian random vector at time step $n$ which has mean vector, $\mathbf{H}^{[n]} \mathbf{x}^{[0]}$, and covariance matrix, $\boldsymbol{\Sigma}^{[n]}$, the result is a new Gaussian random vector with mean vector $\mathbf{H}^{[n+1]} \mathbf{x}^{[0]}$ and covariance matrix, $\mathbf{H}_\Delta^{[n]} \boldsymbol{\Sigma}^{[n]}  \mathbf{H}_\Delta^{[n]}$. Therefore, we can define the ASGN covariance, $\boldsymbol{\Sigma}_\Delta^{[n]}$, as follows:

\begin{gather}
    \boldsymbol{\Sigma}_\Delta^{[n]} = \boldsymbol{\Sigma}^{[n+1]} - \mathbf{H}_\Delta^{[n]} \boldsymbol{\Sigma}^{[n]}  \mathbf{H}_\Delta^{[n]} =  \mathbf{U}^*_\text{DFT}[ \boldsymbol{\Lambda}_{\text{NPS}}^{[n+1]} - \boldsymbol{\Lambda}_{\text{MTF}}^{2 \hspace{0.5mm} [n+1]} \boldsymbol{\Lambda}_{\text{MTF}}^{-2 \hspace{0.5mm} [n]}
    \boldsymbol{\Lambda}_{\text{NPS}}^{[n]} ] \mathbf{U}_\text{DFT} \label{eq:noise_in_terms_of_NPS}
\end{gather}

\noindent So the output of the LSI system and zero-mean ASGN applied to the Gaussian random vector at time step, $n$, is a new Gaussian random vector with mean vector, $\mathbf{H}^{[n+1]} \mathbf{x}^{[0]}$, and covariance matrix, $\boldsymbol{\Sigma}^{[n+1]}$. Note, this relies on the assumption that all eigenvalues (spatial-frequency-dependent variances) of $\boldsymbol{\Sigma}^{[n+1]}$ are greater than or equal to the corresponding eigenvalues of $\mathbf{H}_\Delta^{[n]} \boldsymbol{\Sigma}^{[n]}  \mathbf{H}_\Delta^{[n]}$.

We can substitute \eqref{eq:LSI_in_terms_of_MTF_} and \eqref{eq:noise_in_terms_of_NPS} into \eqref{eq:discrete_forward_update} to arrive at the discrete forward update rule in terms of the prescribed MTF and NPS:

\begin{gather}
    \mathbf{x}^{[n + 1]} = \mathbf{H}^{[n + 1]} {\mathbf{H}^{[n]}}^{\hspace{0mm}-1} \mathbf{x}^{[n]} + (\boldsymbol{\Sigma}^{[n+1]} -  {\mathbf{H}^{[n+1]}}^{\hspace{-0mm} 2} {\mathbf{H}^{[n]}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{[n]} )^{1/2} \boldsymbol{\eta}^{[n]}
    \label{eq:discrete_forward_update_MTF_NPS}
\end{gather}


\subsection{Continuous-Time Process and Stochastic Differential Equations}

\noindent Consider a continuous-time stochastic process, $\mathbf{x}^{(t)}$, given by:

\begin{gather}
\mathbf{x}^{(t)} = \mathbf{H}^{(t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}  1/2} \boldsymbol{\epsilon}^{(t)}  
\label{eq:x_t} \\
\text{p}(\mathbf{x}^{(t)}|\mathbf{x}^{(0)}) = \mathcal{N}(\mathbf{x}^{(t)}; \mathbf{H}^{(t)} \mathbf{x}^{(0)}, {\boldsymbol{\Sigma}^{(t)}}) \label{eq:x_t_dist}
\end{gather}

\noindent where $\boldsymbol{\epsilon}^{(t)}$ is a zero-mean identity-covariance Gaussian process where the updates for non-overlapping time intervals are independent (i.e., a L\'{e}vy process). We define $\mathbf{H}^{(t)}$ and ${\boldsymbol{\Sigma}^{(t)}}$ as continuously differentiable time-dependent spatially-circulant matrices, which control the MTF and NPS, respectively, over time in the stochastic process. 

An instance of the discrete-time forward stochastic process in \eqref{eq:effective_MTF_NPS} can be defined by sampling the continuous-time forward stochastic process in \eqref{eq:x_t_dist} with $N+1$ time points evenly spaced on the interval $t \in (0,T)$ with sample time $\Delta t = T/N$. Note the discrete-time process, $\mathbf{x}^{[n]}$, and the continuous-time process, $\mathbf{x}^{(t)}$ are distinct variables related by this sampling procedure shown below:


\begin{gather}
    \mathbf{x}^{[n]} = \mathbf{H}^{[n]} \mathbf{x}^{[0]} + {\boldsymbol{\Sigma}^{[n]}}^{\hspace{-0mm}  1/2} \boldsymbol{\epsilon}^{[n]} \\
    = \mathbf{x}^{(n \Delta t)} = \mathbf{H}^{(n \Delta t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(n \Delta t)}}^{\hspace{-0mm}  1/2} \boldsymbol{\epsilon}^{(n \Delta t)} 
    \label{eq:sample_discrete}
\end{gather}


In Appendix A, we use the discrete forward update defined in \eqref{eq:discrete_forward_update_MTF_NPS} and take the limit as $\Delta t$ approaches zero to show that the continuous-time process, $\mathbf{x}^{(t)}$, can be described by the following stochastic differential equation:

\begin{equation}
    \mathbf{dx} = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \text{dt} + (\boldsymbol{\Sigma^{'}}^{(t)}  -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )^{1/2} \mathbf{dw} \label{eq:SDE}
\end{equation}

\noindent where $\mathbf{H^{'}}^{(t)} = \frac{\text{d}}{\text{dt}} \mathbf{H}^{(t)} $,  $\boldsymbol{\Sigma^{'}}^{(t)} = \frac{\text{d}}{\text{dt}} \boldsymbol{\Sigma}^{(t)}$, and $\mathbf{dw}$ is infinitesimal white Gaussian noise with covariance, $\text{dt} \mathbf{I}$. The stochastic differential equation in \eqref{eq:SDE} is one of the main results of this work. It enables Fourier diffusion models with prescriptive control of MTF and NPS as a function of time in the forward and reverse stochastic processes. 

If we compare $\eqref{eq:SDE}$ to the standard form, 

\begin{equation}
    \mathbf{dx} = \mathbf{f}(\mathbf{x}, t) \text{dt} + \mathbf{G}(t) \mathbf{dw},
\end{equation}

\noindent then we can identify,

\begin{gather}
    \mathbf{f}(\mathbf{x}, t) = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \hspace{2mm},\hspace{4mm} 
    \mathbf{G}(t) = (\boldsymbol{\Sigma^{'}}^{(t)}  -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )^{1/2} .
    \label{eq:f_g}
\end{gather}

It has previously been shown there is an exact solution for the time-reversed stochastic differential equation \cite{anderson1982reverse}\cite{song2020score} The formula is shown below:

\begin{equation}
    \mathbf{dx} = [\mathbf{f}(\mathbf{x}, t) - \mathbf{G}(t) {\mathbf{G}(t)}^T \nabla \log{\text{p} (\mathbf{x}^{(t)})}] \text{dt} + \mathbf{G}(t) \mathbf{dw}.
    \label{eq:reverse_sde_standard_form}
\end{equation}

\noindent The inclusion of the score function, $\nabla \log{\text{p} (\mathbf{x}^{(t)})}$, results in a deterministic drift towards higher probability values of $\mathbf{x}^{(t)}$. Substituting the values in \eqref{eq:f_g} into \eqref{eq:reverse_sde_standard_form} results in the following formula for the reverse stochastic differential equation for Fourier diffusion models:

\begin{gather}
     \mathbf{dx} \hspace{-1mm} = \hspace{-1mm} [\mathbf{H^{'}}^{(t)} \hspace{-.5mm} {\mathbf{H}^{(t)}}^{\hspace{-.5mm}-1} \hspace{-2mm}\mathbf{x}^{(t)} \hspace{-1mm} - \hspace{-1mm}(\boldsymbol{\Sigma^{'}}^{(t)}  \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )  \nabla \log{\text{p} (\mathbf{x}^{(t)})}] \text{dt} + (\boldsymbol{\Sigma^{'}}^{(t)}   \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )^{1/2} \mathbf{dw} .
    \label{eq:reverse_SDE_unconditional}
\end{gather}


Most existing diffusion models for image generation use a forward stochastic process defined by additive white Gaussian noise and if there is any deterministic drift, it is almost always by scalar multiplication of the image signal, usually causing it to decay towards zero. We refer to these as scalar diffusion models, and they are a special case of Fourier models, where $\mathbf{H}^{(t)}$ and $\boldsymbol{\Sigma}^{(t)}$ are set to scalar matrices (identity times a time-dependent scalar) as shown below:

\begin{gather}
    \mathbf{H}^{(t)} = e^{- \frac{1}{2}\int_0^t \beta(s)\text{ds}}\hspace{1mm} \mathbf{I} \label{eq:scalar_drift}\\
    \boldsymbol{\Sigma}^{(t)} = \sigma^2(t) \hspace{1mm} \mathbf{I} \label{eq:scalar_drift}
\end{gather}

\noindent which results in the forward stochastic differential equation:

\begin{gather}
    \mathbf{dx} = -\frac{1}{2} \beta(t) \mathbf{x}^{(t)}\text{dt} + \sqrt{\beta(t)\sigma^2(t) + \frac{\text{d}}{\text{dt}}\sigma^2(t)}\mathbf{dw} ,
    \label{eq:white_noise}
\end{gather}

\noindent where $\sigma^2(t)$ controls the so-called variance-exploding (VE) component and $\beta(t)$ controls the variance-preserving component (VP) as defined in \cite{song2020score}. Note that $\beta(t)$ is a function of time, not necessarily a constant exponential decay, so there is no loss of generality and any differentiable magnitude function can be achieved with this parameterization. For the special case of the original denoising diffusion probabilistic models \cite{sohl2015deep} \cite{ho2020denoising}, there is the additional constraint, $\sigma^2(t) = 1 - e^{-\int_0^{t}\beta(s)\text{ds}}$, meaning the process is fully defined by $\beta(t)$. 

One way to interpret Fourier diffusion models is to consider them as conventional diffusion models in the spatial frequency domain with spatial-frequency-dependent diffusion rates. For example, it would be mathematically equivalent to take the two-dimensional Fourier transform of the training images, and then train a diagonal diffusion model (using diagonal matrices for spatial-frequency dependent diffusion rates) to generate new samples of those Fourier coefficients. One practical advantage of formulating the process with LSI systems in the image domain is that the reverse time steps may be more suitable for approximation with convolutional neural networks, which are also composed of shift-invariant operations.

\subsection{Conditional Image Generation and Supervised Learning}

The reverse-time stochastic differential equation in \eqref{eq:reverse_SDE_unconditional} applies to unconditional image generation with Fourier diffusion models. Assuming we have access to the score function, $\nabla \log{\text{p} (\mathbf{x}^{(t)})}$ or an approximation thereof, and  assuming the distribution of the endpoint, $\text{p}(\mathbf{x}^{(T)})$, is a known prior, we can use \eqref{eq:reverse_SDE_unconditional} to run the reverse-time process and generate new samples from $\text{p}(\mathbf{x}^{(0)})$ which typically represents the training data distribution. 

In this work, we consider the case where samples of both the target images, $\mathbf{x}^{(0)}$, and some corresponding measurements, $\mathbf{y}$, are available at training time. Our goal is to train a deep learning model to sample from the posterior distribution $\text{p}(\mathbf{x}^{(0)}|\mathbf{y})$. For this work, we will consider the following forward model:

% It is also useful for many practical applications to consider the case of conditional image generation, where we have access to additional information to help guide the reverse process. We model by this additional information by a random vector, $\mathbf{y}$, which we refer to as the measurements. Note that for the purposes of this section, we do not need a specific definition of the measurement likelihood, $\text{p}(\mathbf{y}|\mathbf{x}^{(0)})$. Rather, we assume the measurement likelihood will depend on the specific application and in this section, we deal with more general expressions about conditional image generation. 

% Our goal is to use the measurements as extra information to guide the reverse process and generate samples from the posterior distribution $\text{p}(\mathbf{x}^{(0)}|\mathbf{y})$. The conditional reverse process is given by the following stochastic differential equation:

\begin{gather}
    \mathbf{y} = \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}} \mathbf{x}^{(0)} + \boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}}^{1/2} \boldsymbol{\varepsilon} \\
    \text{p}(\mathbf{y}|\mathbf{x}^{(0)}) = \mathcal{N}(\mathbf{y}; \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}} \hspace{0.5mm} \mathbf{x}^{(0)}, \boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}})
    \label{eq:forward_model}
\end{gather}

\noindent where $\boldsymbol{\varepsilon}$ is a zero-mean identity-covariance Gaussian random vector, $\mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}}$ is circulant matrix representing the MTF of the measurements, and $\boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}}$ is a circulant matrix representing the NPS of the measurements. 


% \begin{equation}
%     \mathbf{dx} = [\mathbf{f}(\mathbf{x}, t) - \mathbf{g}^2(t) \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y})}] \text{dt} + \mathbf{g}(t) \mathbf{dw}.
%     \label{eq:reverse_sde_standard_form}
% \end{equation}

% \noindent We will continue to use the formulae for measurement-conditioned image generation with the understanding that the unconditional case can be obtained by substituting the empty set, $\mathbf{y}=\emptyset$, resulting in $\log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y})} = \log{\text{p} (\mathbf{x}^{(t)})}$.  Substituting the values in \eqref{eq:f_g} into \eqref{eq:reverse_sde_standard_form} results in the following formula for the reverse stochastic differential equation:

% \begin{gather}
%      \mathbf{dx} \hspace{-1mm} = \hspace{-1mm} [\mathbf{H^{'}}^{(t)} \hspace{-.5mm} {\mathbf{H}^{(t)}}^{\hspace{-.5mm}-1} \hspace{-2mm}\mathbf{x}^{(t)} \hspace{-1mm} - \hspace{-1mm}(\boldsymbol{\Sigma^{'}}^{(t)}  \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )  \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y})}] \text{dt} + (\boldsymbol{\Sigma^{'}}^{(t)}   \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )^{1/2} \mathbf{dw} .
% \end{gather}



% There are several approaches to implementing this type of conditional image generation. First, we consider the case where only unsupervised learning data (i.e., samples from $p(\mathbf{x}^{(0)})$) are available at training time, but we also assume we have a separate and known likelihood model, $\text{p}(\mathbf{y} | \mathbf{x}^{(t)})$. As suggested by \cite{song2020score}, in this case it makes sense to expand the posterior score function using Bayes rule as follows:


% \begin{gather}
%      \mathbf{dx} = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \text{dt} \nonumber \\
%      -(\boldsymbol{\Sigma^{'}}^{(t)}  \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} ) \nabla \log{\text{p} (\mathbf{x}^{(t)})} \text{dt} \nonumber \\
%       -(\boldsymbol{\Sigma^{'}}^{(t)}  \hspace{-3mm} -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} ) \nabla_{\mathbf{x}^{(t)}}\log{\text{p} (\mathbf{y}|\mathbf{x}^{(t)})}) \text{dt} \nonumber \\
%      (-  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \boldsymbol{\Sigma^{'}}^{(t)}  )^{1/2} \mathbf{dw} .
% \end{gather}

% \noindent One benefit of this approach is that one can train the neural network to approximate the unconditional score function, $\nabla \log{\text{p} (\mathbf{x}^{(t)})}$, one time, and then use the same prior together with any additional information, $\mathbf{y}$, as long as the likelihood score function $\nabla_{\mathbf{x}^{(t)}}\log{\text{p} (\mathbf{y}|\mathbf{x}^{(t)})}$ is well-defined. However, this is not always the case. For example, in CT physical modeling and image reconstruction, one may have a well-defined measurement likelihood score function $\nabla_{\mathbf{x}^{(0)}}\log{\text{p} (\mathbf{y}|\mathbf{x}^{(0)})}$, such as used for iterative image reconstruction, but the time dependent score function $\nabla_{\mathbf{x}^{(t)}}\log{\text{p} (\mathbf{y}|\mathbf{x}^{(t)})}$ is much harder to define and will depend on the time-dependent MTF and NPS. There have been efforts to address this issue using a dual-domain stochastic process \cite{song2021solving} but we will not focus on that here.  


As shown in Figure \ref{fig:conditional_options}, there are at least two possible causal relationships between the stochastic process, $\mathbf{x}^{(t)}$, and the measurements, $\mathbf{y}$. The first option shows measurements as outside information, where $\mathbf{y}$ is a stochastic function of $\mathbf{x}^{(0)}$, but separate from the forward process. In that case, we assume that $\text{p}(\mathbf{x}^{(T)}|\mathbf{y})$ is a known prior, which we can use to initialize the  reverse process, and we replace the unconditional score function in \eqref{eq:reverse_SDE_unconditional} with the posterior score function, $\nabla\log\text{p}(\mathbf{x}^{(t)}|\mathbf{y})$. The second option in Figure \ref{fig:conditional_options} shows measurements as the final time step. In that case, we can use the reverse process defined in \eqref{eq:reverse_SDE_unconditional} without modification. By initializing with the measurements, $\mathbf{y}$, the final step of the reverse process at $t=0$ will be a sample from $\text{p}(\mathbf{x}^{(0)}|\mathbf{y})$.


In this work, we evaluate and compare scalar diffusion models with Fourier diffusion models for conditional image generation.  For the forward model defined in \eqref{eq:forward_model}, scalar diffusion models cannot generally be used for the second option, with measurements as the last time step. This is one of the most important new capabilities of Fourier diffusion models; the forward process can be crafted such that the MTF and NPS at the final time step of the forward process are exactly equal to the measurement MTF and NPS. That is, $\mathbf{H}^{(T)} = \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}}$, and, $\boldsymbol{\Sigma}^{(T)}=\boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}}$. In this way, Fourier diffusion models can describe continuous probability flow from the ground truth images to measured images with shift-invariant blur and stationary correlated noise. 


% Since the posterior score function, $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y})}$, is a function of $\mathbf{x}^{(t)}$ and $\mathbf{y}$, we propose to directly approximate it using a neural network with $\mathbf{x}^{(t)}$, $\mathbf{y}$, and $t$ as inputs as shown in Figure \ref{fig:unet_diagram}. The advantage of our proposed approach is that we do not need a model for $\nabla_{\mathbf{x}^{(t)}}\log{\text{p} (\mathbf{y}|\mathbf{x}^{(t)})}$ since this is part of what the network is trained to approximate. The drawback is that it requires a supervised training dataset of $(\mathbf{x}^{(0)}, \mathbf{y})$ pairs, and it needs to be re-trained for new types of measurements. 

% One of the advantages of Fourier diffusion models for image restoration is the capability to model continuous probability flow from ground truth images to image-domain measurements, assuming those measurements are well-described by a certain MTF and NPS. There are at least two possible frameworks for relationships between $\mathbf{x}^{(t)}$ and, $\mathbf{y}$ as shown in Figure \ref{fig:conditional_options}. The first option is to assume the final time step $\mathbf{x}^{(T)}$ is the same random variable as the measurements, $\mathbf{y}$. The second option is to consider the measurements as outside information completely separate from the forward or reverse stochastic process. Either is possible, but they must be handled correctly during training. One advantage of the first option is that the measurements can be used directly as the final time step to initialize the reverse sampling process. One advantage of the second option is that it can apply more generally to any type of additional information, not only image domain measurements. 
% For example, one could potentially use sinogram-domain measurements in CT imaging or k-space measurements in MRI imaging to guide the reverse stochastic process. One could also use completely different types of outside information like patient-specific metrics, or even natural language inputs if using the second option. 




\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/conditional_options.png}
    \caption{Two options for causal relationships between stochastic process and measurements. The second option is only possible with Fourier diffusion models. In this work, we evaluate and compare scalar diffusion models using the first option and Fourier diffusion models using the second option. }
    \label{fig:conditional_options}
\end{figure}




\subsection{Score-Matching Loss Function for Neural Network Training}

\noindent It is possible to train a neural network to estimate the score function in order to run an approximation of the reverse process, allowing for conditional or unconditional generative modeling. We assume the inputs of the neural network are the image at a certain time step, $\mathbf{x}^{(t)}$, the measurements, $\mathbf{y}$, and the time, $t$, so we define the neural network by the function, $\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t)$, parameterized by the network weights $\boldsymbol{\theta}$. During training, we start with a sample from $\mathbf{x}^{(0)}$. Next, we uniformly sample the time, $t\in (0,T)$, and we generate a corresponding sample from $\mathbf{x}^{(t)}$ given $\mathbf{x}^{(0)}$ using \eqref{eq:x_t} and the pre-defined time-dependent matrices, $\mathbf{H}^{(t)}$ and $\boldsymbol{\Sigma}^{(t)}$, which describe the effective MTF and NPS. Finally, we generate a sample from $\mathbf{y}$ given $\mathbf{x}^{(0)}$ and $\mathbf{x}^{(t)}$. If using the first option, in Figure \ref{fig:conditional_options}, where measurements are treated as outside information, then $\mathbf{y}$ is conditionally independent of $\mathbf{x}^{(t)}$ given $\mathbf{x}^{(0)}$, so we can generate $\mathbf{y}$ as a stochastic function of $\mathbf{x}^{(0)}$ using \eqref{eq:forward_model}. If using the second option in Figure \ref{fig:conditional_options}, where the measurements are the last time step, we can view $\mathbf{y}$ as a stochastic function of $\mathbf{x}^{(t)}$ and sample it using the following formula:

\begin{gather}
    \mathbf{y} = \mathbf{H}^{(T)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} + (\boldsymbol{\Sigma}^{(T)} -  {\mathbf{H}^{(T)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{[n]} )^{1/2} \boldsymbol{\zeta} \\
    \text{p}(\mathbf{y}|\mathbf{x}^{(t)})  = \mathcal{N}(\mathbf{y}; \mathbf{H}^{(T)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)}, \boldsymbol{\Sigma}^{(T)} -  {\mathbf{H}^{(T)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{(t)})
    \label{eq:option_2_sample_y}
\end{gather}


\noindent where $\boldsymbol{\zeta}$ is a zero-mean identity-covariance Gaussian random vector.  The logic for this formula is very similar to the logic in the derivation of \eqref{eq:discrete_forward_update_MTF_NPS}. Applying $\mathbf{H}^{(T)}{\mathbf{H}^{(t)}}^{-1}$ to $\mathbf{x}^{(t)}$ and adding $(\boldsymbol{\Sigma}^{(T)} -  {\mathbf{H}^{(T)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{(t)})$ will result in a new Gaussian random variable $\mathbf{x}^{(T)}=\mathbf{y}$ with mean vector $\mathbf{H}^{(T)} \mathbf{x}^{(0)} = \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}} \mathbf{x}^{(0)}$ and covariance, $\boldsymbol{\Sigma}^{(T)} = \boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}}$

We train the network with samples from the supervised training data, $(\mathbf{x}^{(0)}, \mathbf{x}^{(t)}, \mathbf{y}, t)$, and minimize the mean squared error between the predicted score, $\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t)$, and the target score, $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}$, (known as the Jensen-Fisher divergence \cite{sanchez2012jensen}) as shown below:

\begin{gather}
    \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}||^2] .
    \nonumber \\
    =\underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}-1} (\mathbf{x}^{(t)} - \mathbf{H}^{(t)} \mathbf{x}^{(0)})   ||^2].
    \label{eq:score_matching_loss}
\end{gather}

Note that $\mathbf{x}^{(0)}$ is available at training time to evaluate the score function, $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}$, but not at test time. In this supervised learning approach, $\mathbf{y}$ is available at both training and testing time, so it is used as a network input. Since $\mathbf{y}$ is a stochastic function of $\mathbf{x}^{(0)}$, it may contain information about the target image that is useful for improving score prediction.

The training loss function in \eqref{eq:score_matching_loss} is valid for both options in Figure \ref{fig:conditional_options}. For the first option, with measurements as outside information, we can use the property that  $\mathbf{y}$ is conditionally independent of $\mathbf{x}^{(t)}$ given $\mathbf{x}^{(0)}$. Since $\mathbf{x}^{(0)}$ is given at training time, we can make the substitution: $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)}, \mathbf{y} )}$ = $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}$. Therefore, \eqref{eq:score_matching_loss} is valid to approximate $\nabla \log \text{p}(\mathbf{x}^{(t)}| \mathbf{y})$ in the case where measurements are considered to be outside information. For the second option, with measurements as the final time step, we seek to approximate $\nabla \log \text{p}(\mathbf{x}^{(t)})$; so, \eqref{eq:score_matching_loss} is also valid for that case.




% For conditional image generation using the first option in Figure \ref{fig:conditional_options}, the measurements are considered to be the image at the last time step, at $T$, in the forward process. In that case, we can use Bayes rule to expand the posterior score function as follows:

% \begin{equation}
%     \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y}}, \mathbf{x}^{(0)}) = \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)}})  + \nabla_{\mathbf{x}^{(t)}} \log{\text{p} (\mathbf{y} | \mathbf{x}^{(t)})} 
% \end{equation}

% \noindent Here, we have also used the properties $\nabla \log{\text{p} (\mathbf{y} | \mathbf{x}^{(0)})} =0$ since there is no dependence on $\mathbf{x}^{(t)}$, and  $\nabla \log{\text{p} (\mathbf{y} | \mathbf{x}^{(0)},  \mathbf{x}^{(t)})}  = \nabla_{\mathbf{x}^{(t)}} \log{\text{p} (\mathbf{y} | \mathbf{x}^{(t)})} $, since $\mathbf{y}$ is conditionally independent of $\mathbf{x}^{(0)}$, given $\mathbf{x}^{(t)}$.  Since we know the probability density functions are 

% \begin{gather}
% \text{p} (\mathbf{x^{(t)}} | \mathbf{x}^{(0)}) = \mathcal{N}(\mathbf{x}^{(t)}; \mathbf{H}^{(t)}\mathbf{x}^{(0)}, \boldsymbol{\Sigma}^{(t)}) \\
% \text{p} (\mathbf{y} | \mathbf{x}^{(t)}) = \mathcal{N}(\mathbf{y}; {\mathbf{H}^{(1)}}{\mathbf{H}^{(t)}}^{-\hspace{-3mm} -1}\mathbf{x}^{(t)},  \boldsymbol{\Sigma}^{(1)}  - {\mathbf{H}^{(1)}}^{\hspace{0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2}\boldsymbol{\Sigma}^{(t)})
% \end{gather}

% \noindent where $\mathbf{H}^{(1)}$ $\boldsymbol{\Sigma}^{(1)}$ are the MTF and NPS at the final time step, $T$, and therefore describe the image quality of $\mathbf{y}$. We can substitute the score functions into \eqref{eq:fisher_divergence} as follows:

% \begin{gather}
%     \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)}})  - \nabla_{\mathbf{x}^{(t)}} \log{\text{p} (\mathbf{y} | \mathbf{x}^{(t)})} ||^2] \\
%     =\underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}-1} (\mathbf{x}^{(t)} - \mathbf{H}^{(t)} \mathbf{x}^{(0)})  \nonumber \\ - (\boldsymbol{\Sigma}^{(1)}  - {\mathbf{H}^{(1)}}^{\hspace{0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2}\boldsymbol{\Sigma}^{(t)})^{-1}(\mathbf{y} - {\mathbf{H}^{(1)}}{\mathbf{H}^{(t)}}^{ -1}\mathbf{x}^{(t)} ) ||^2] .
%     \label{eq:posterior_score_matching}
% \end{gather}


% For conditional image generation using the second option in Figure \ref{fig:conditional_options}, we can assume that, $\mathbf{x}^{(t)}$, is conditionally independent of the measurements, $\mathbf{y}$, given the true images, $\mathbf{x}^{(0)}$, 
% which means, $\nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y}}, \mathbf{x}^{(0)}) = \nabla \log{\text{p}(\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}$. Therefore, the score-matching loss function used for neural network training is the Fisher divergence between the model and data distributions, as shown below:

% \begin{gather}
%     \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{x}^{(0)})}||^2]\\
%     \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[||\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - {\boldsymbol{\Sigma}^{(t)}}^{\hspace{-2mm}-1} (\mathbf{x}^{(t)} - \mathbf{H}^{(t)} \mathbf{x}^{(0)}) ||^2]
% \end{gather}

% \noindent Using the parameterization, $\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) = {\boldsymbol{\Sigma}^{(t)}}^{\hspace{-2mm}-1/2} \boldsymbol{\hat{\epsilon}}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t)$, leads to the following:

% \begin{equation}
% \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[(\boldsymbol{\hat{\epsilon}}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \boldsymbol{\epsilon}^{(t)})^T {\boldsymbol{\Sigma}^{(t)}}^{\hspace{-2mm}-1} (\boldsymbol{\hat{\epsilon}}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \boldsymbol{\epsilon}^{(t)}) ] \label{eq:score_matching_loss}
% \end{equation}

After the score-matching neural network is trained, one can run a discrete-time approximation of the reverse process using the Euler-Maryuama method, as shown below:

\begin{gather}
     \mathbf{x}^{[n-1]} = \mathbf{x}^{[n]} - [\mathbf{H^{'}}^{(n\Delta t)}{\mathbf{H}^{(n \Delta t)}}^{\hspace{0mm}-1} \mathbf{x}^{[n]} - (-  2 {\mathbf{H^{'}}^{(n \Delta t)}} {\mathbf{H}^{(n \Delta t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(n \Delta t)} + \boldsymbol{\Sigma^{'}}^{(n \Delta t)} )  \mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}, \mathbf{y}, n\Delta t)] \Delta t \nonumber \\
    \hspace{70mm} + (-  2 {\mathbf{H^{'}}^{(n \Delta t)}} {\mathbf{H}^{(n\Delta t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(n \Delta t)} + \boldsymbol{\Sigma^{'}}^{(n\Delta t)}  )^{1/2} \sqrt{\Delta t} \boldsymbol{\zeta}^{[n]} \label{eq:euler-maryuama}
\end{gather}

\noindent where $\boldsymbol{\zeta}^{[n]}$ is zero-mean identity-covariance Gaussian noise with independent time steps. 



%  While we were originally motivated by the goal of controlling MTF and NPS in the forward process, the derivations in the previous sections have not relied on any special properties of circulant matrices.  Therefore, we can write another more general version of these equations that applies any Gaussian stochastic process composed of linear systems and additive Gaussian noise without specifying shift invariant systems or stationary noise. We show the general version of this stochastic differential equations, score-matching loss function, and reverse process sampling procedure in Appendix B.  For the experiments in the following section, we focus on the forward process in \eqref{eq:x_t} and score-matching loss function in \eqref{eq:score_matching_loss} using cirulant matrices to train measurement-conditioned Fourier diffusion models for medical image restoration. In the future, we are interested in exploring other applications of the more general equations above.






\newpage
\subsection{Experimental Methods: Low-Dose CT Image Restoration}

In this section, we describe an implementation of our proposed method for low-dose CT image restoration. We used the publicly available Lung Image Database Consortium (LIDC) dataset, which consists of three-dimensional image volumes reconstructed from thoracic CT scans for lung imaging. The first 80\% of image volumes were used for training data and the last 20\% were reserved for validation data. We randomly extracted 8000 two-dimensional axial slices from the training volumes and 2000 axial slices from the validation volumes. The slices were registered to a common coordinate system using bilinear interpolation so that all images are $512\times512$ with $1.0$~mm voxel spacing. The image values were shifted and scaled such that 0.0 represents -1000~HU and 10.0 represents 1000~HU. The reason we chose this scale was so that we can use zero-mean identity-covariance Gaussian noise as the final time step of scalar diffusion models and the noise standard deviation will be comparable to the measurements as shown in Figure \ref{fig:MTF_NPS_vs_time_scalar}.  These images were used as the ground-truth for training and validation; however, it is important to note that these images still contain errors such as noise, blur, and artifacts. These errors are part of the target training distribution, so they may impact the results for the trained diffusion models. Our approach is to simulate lower-quality images that one may measure with a low-radiation-dose CT scan by applying convolutional blur and adding stationary noise. These low-quality CT images represent the output of a low-dose CT scan, so they are treated as the measurements for the purposes of this study. Our goal is to train conditional score-based diffusion models to sample posterior estimate images given low-dose CT measurements. If successful, the posterior estimate images sampled by the trained model should have similar image quality to the normal-dose training images in the LIDC dataset. 

% \subsubsection{Parameterizing MTF and NPS Trajectories with Band-Pass Filters}

% Our proposed approach involves prescribing the MTF and NPS at each stage in the forward process. 
For this implementation, we chose to parameterize both MTF and NPS using a set of band-pass filters.  Let the matrix $\boldsymbol{\mathcal{G}}(h) =  \mathbf{U}^*_\text{DFT} \boldsymbol{\Lambda}_{\boldsymbol{\mathcal{G}}}(h) \mathbf{U}_\text{DFT}$ represent an isotropic Gaussian low-pass filter in the two-dimensional spatial frequency domain, where $h$ describes the PSF full width at half maximum in units of $\text{mm}$.  That is, the diagonal of $\boldsymbol{\Lambda}_{\boldsymbol{\mathcal{G}}}(h)$ is the Fourier transform of a convolutional Gaussian blur kernel proportional to $\exp{(-\frac{1}{2} (\sqrt{x^2 + y^2})^2 / \sigma^2(h))}$ where $\sigma(h)=(2\sqrt{2\log{2}})^{-1}h \approx (0.425) h$.  We used the following parameterization of low-pass, band-pass, and high-pass filters:

\begin{gather}
    \mathbf{H}_\text{LPF} = \boldsymbol{\mathcal{G}}(3.0~\text{mm}) \\
    \mathbf{H}_\text{BPF} = \boldsymbol{\mathcal{G}}(1.0~\text{mm}) - \boldsymbol{\mathcal{G}}(3.0~\text{mm}) \\
    \mathbf{H}_\text{HPF} = \mathbf{I} - \boldsymbol{\mathcal{G}}(1.0~\text{mm}) 
\end{gather}

\noindent Our model of low-dose CT measurements, $\mathbf{y}$, given the ground truth image, $\mathbf{x}$ is

\begin{gather}
    \text{p}(\mathbf{y}|\mathbf{x}^{(0)}) = \mathcal{N}(\mathbf{y}; \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}} \hspace{0.5mm} \mathbf{x}^{(0)}, \boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}})\\
    \mathbf{H}_{\mathbf{y}|\mathbf{x}^{(0)}} = (1.0) \enspace \mathbf{H}_\text{LPF}  + (0.5) \enspace \mathbf{H}_\text{BPF}  + (0.1) \enspace \mathbf{H}_\text{HPF} \\ 
    \boldsymbol{\Sigma}_{\mathbf{y}|\mathbf{x}^{(0)}} = (0.1) \enspace \mathbf{H}_\text{LPF}  + (1.0) \enspace \mathbf{H}_\text{BPF}  + (0.5) \enspace \mathbf{H}_\text{HPF}  
\end{gather}

\noindent This particular choice of measured MTF and NPS is arbitrary but intended to roughly match the typical patterns observed in low-dose CT images. In general, one can substitute the MTF and NPS to match the calibrated values for a medical imaging system.

In this experiment, we compare two cases: 1) scalar diffusion models using multiplicative drift and additive white Gaussian noise and 2) Fourier diffusion models using linear shift invariant systems and additive stationary Gaussian noise. As shown in \eqref{eq:scalar_drift} and \eqref{eq:white_noise}, scalar diffusion models are a special case of Fourier diffusion models that can be written using time-dependent scalar matrices. We define the scalar diffusion model using the following parameters:

\begin{gather}
    \mathbf{H}^{(t)} = (e^{-  
 5t^2})\hspace{1mm} \mathbf{I} \label{eq:scalar_diffusion_model_drift}\\
    \boldsymbol{\Sigma}^{(t)} = (1 - e^{- 10 t^2}) \hspace{1mm} \mathbf{I} \label{eq:scalar_diffusion_model_noise}
\end{gather}

\noindent This forward stochastic process begins with $\mathbf{x}^{(0)}$ having the same distribution as the true images and converges to approximately zero-mean identify-covariance Gaussian noise at the final time step, $\mathbf{x}^{(T)}$. For the Fourier diffusion model case, we design the forward stochastic process so that the final time step has the same distribution as the low-dose CT measurements. This capability to model continuous probability flow from true images to measured images is one of the key benefits of Fourier diffusion models. For this case, we use the formulae shown below:

\begin{gather}
    \mathbf{H}^{(t)} = (1.0) \enspace \mathbf{H}_\text{LPF}  + (0.5 + 0.5e^{-5t^2}) \enspace \mathbf{H}_\text{BPF}  + (0.1 + 0.9e^{-5t^2}) \enspace \mathbf{H}_\text{HPF} \\ 
    \boldsymbol{\Sigma}^{(t)} = (0.1 - 0.1 e^{- 10 t^2}) \enspace \mathbf{H}_\text{LPF}  + (1.0 - 1.0 e^{- 10 t^2}) \enspace \mathbf{H}_\text{BPF}  + (0.5 - 0.5 e^{- 10 t^2}) \enspace \mathbf{H}_\text{HPF}  
\end{gather}


\begin{figure}
    \centering
    \includegraphics[trim={0 0 0 0},clip,width=0.82\textwidth]{figures/score_matching_nn_diagram.png}
    \caption{Diagram of the score-matching neural network. The inputs are the forward process sample, low-dose CT measured image, and sample time. The output is the predicted score.  }
    \label{fig:unet_diagram}
\end{figure}

\begin{figure}[h!]
    \centering
\includegraphics[trim={0 3mm 0 8mm},clip,width=0.43\textwidth]{figures/MTF_vs_time_scalar.png}
\includegraphics[trim={0 3mm 0 8mm},clip,width=0.43\textwidth]{figures/NPS_vs_time_scalar.png}
    \caption{MTF  and NPS vs time for the scalar diffusion model. }
    \label{fig:MTF_NPS_vs_time_scalar}
\end{figure}


\begin{figure}[h!]
    \centering
\includegraphics[trim={0 3mm 0 8mm},clip,width=0.43\textwidth]{figures/MTF_vs_time_fourier.png}
\includegraphics[trim={0 3mm 0 8mm},clip,width=0.43\textwidth]{figures/NPS_vs_time_fourier.png}
    \caption{MTF and NPS vs time for the Fourier diffusion model. }
    \label{fig:MTF_NPS_vs_time_fourier}
\end{figure}

For the score-matching neural network, we used the u-net architecture shown in Figure \ref{fig:unet_diagram}. The model inputs are the forward process sample, the low-dose CT measurements, and the sample time. The model output is an estimation of the score function. For time encoding, we applied a multi-layer perceptron to the sample time and converted the output to constant-valued images. The forward process sample image, the low-dose CT measured image, and the time encoding images are concatenated and passed to the score-matching u-net. Each convolutional block consists of a convolutional layer, rectified linear units activation, and batch normalization. The final output layer has no activation function (linear) or batch normalization. Dropout layers were also applied to each convolutional block with a drop out rate of 20\%.  We used the Adam optimizer with a learning rate of $10^{-3}$ \cite{kingma2014adam}. All machine learning modules were implemented with in Pytorch \cite{NEURIPS2019_9015}. We ran 10,000 training epochs, 32 images per batch, and the training loss function in \eqref{eq:score_matching_loss}, where the expectation over $\mathbf{x}^{(0)}$ is implemented via the sample mean over multiple training images per batch and the expectation over time, $t$, is implemented by sampling a different time step independently for each image so that there are also 32 time samples per batch.

After training, we run the reverse process using \eqref{eq:euler-maryuama} for both diffusion models. We discretize the reverse process with 1024, 512, 256, 128, 64, 32, 16, 8 and 4 time steps uniformly spaced between $t=0$ and $T$, inclusively. That way, we can analyze the error due to time discretization for scalar and Fourier diffusion models. We ran the reverse process 32 times using the same measurements. For the posterior estimates at $t=0$ of the reverse process, we compute the mean squared error, mean squared bias, and mean variance where the mean refers to a spatial average over the image, error/bias are with respect to the ground truth and the variance refers to the ensemble of samples from the reverse process.



\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip, width=0.99\textwidth]{figures/process_scalar_1024.png}
    \caption{Forward and reverse stochastic process for the scalar diffusion model with 1024 time steps applied to a full CT image.  }
    \label{fig:process_scalar_1024}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_fourier_1024.png}
    \caption{Forward and reverse stochastic process for the Fourier diffusion model with 1024 time steps applied to a full CT image.  }
    \label{fig:process_fourier_1024}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_scalar_16.png}
    \caption{Forward and reverse stochastic process for the scalar diffusion model with 16 time steps applied to a full CT image.  }
    \label{fig:process_scalar_16}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_fourier_16.png}
    \caption{Forward and reverse stochastic process for the Fourier diffusion model with 16 time steps applied to a full CT image. }
    \label{fig:process_fourier_16}
\end{figure}






\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_patch_scalar_1024.png}
    \caption{Forward and reverse stochastic process for the scalar diffusion model with 1024 time steps applied to an image patch showing a lung nodule.  }
    \label{fig:process_patch_scalar_1024}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_patch_fourier_1024.png}
    \caption{Forward and reverse stochastic process for the Fourier diffusion model with 1024 time steps applied to an image patch showing a lung nodule. }
    \label{fig:process_patch_fourier_1024}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_patch_scalar_16.png}
    \caption{Forward and reverse stochastic process for the scalar diffusion model with 16 time steps applied to an image patch showing a lung nodule.  }
    \label{fig:process_patch_scalar_16}
\end{figure}

\begin{figure}[ht!]
    \centering
\includegraphics[trim={50mm 20mm 50mm 20mm},clip,width=0.99\textwidth]{figures/process_patch_fourier_16.png}
    \caption{Forward and reverse stochastic process for the Fourier diffusion model with 16 time steps applied to an image patch showing a lung nodule. }
    \label{fig:process_patch_fourier_16}
\end{figure}

\vspace{-4mm}

\section{Results}

An example of the forward and reverse process for scalar diffusion models is displayed in Figure \ref{fig:process_scalar_1024} for a full CT image and Figure \ref{fig:process_patch_scalar_1024}  for a zoomed patch showing a lung nodule. This shows the existing method for diffusion models, which will be our reference to evaluate our new proposed method. The forward process is initialized, at $t=0$, with the ground truth images. The signal fades to zero over time in the forward process, and Gaussian white noise is added at each time step. The final result is approximately zero-mean identity-covariance Gaussian noise. The score matching neural network is trained to run the reverse process, sampling high quality images given low-radiation-dose  CT measurements. For the processes shown in Figure  \ref{fig:process_scalar_1024} and Figure \ref{fig:process_patch_scalar_1024}, we used 1024 time steps to run the reverse process. Comparing the top row and the bottom row, the samples from the reverse process appear to have similar image quality to the forward process. The final result of the reverse process at $t=0$ is a posterior estimate, or an approximation of the ground truth, given the low-radiation-dose CT measurements. Examples of the Fourier diffusion model with 1024 time steps are shown in Figure \ref{fig:process_fourier_1024} and \ref{fig:process_fourier_16}. The forward process for this case begins with the true images at $t=0$ and converges to the same distribution as the measured images at $T$. Note the final column of the Fourier diffusion model shows an example from the same distribution as the measured images. All the reverse processes in these Figures are for conditional image generation; so both the scalar and Fourier diffusion models are guided by measurements with the same image quality shown at $T$ in the Fourier diffusion models.


Figures \ref{fig:process_scalar_1024}, \ref{fig:process_fourier_1024}, \ref{fig:process_patch_scalar_1024}, and \ref{fig:process_patch_fourier_1024} use 1024 time steps, which means one reverse process sample requires 1024 passes of the score-matching neural network. Corresponding examples using only 16 time steps are shown in Figures \ref{fig:process_scalar_16}, \ref{fig:process_fourier_16}, \ref{fig:process_patch_scalar_16},  and  \ref{fig:process_patch_fourier_16}, respectively. For the case of the scalar diffusion model with fewer time steps shown in Figure \ref{fig:process_scalar_16} and Figure \ref{fig:process_patch_scalar_16}, the image quality in the reverse process is much worse than the forward process. Comparing the 1024 time step reverse process, shown in Figure \ref{fig:process_scalar_1024}, with the 16 time step reverse process, shown in Figure \ref{fig:process_fourier_16}, the increased error is most likely due to time discretization. Figure \ref{fig:process_patch_fourier_16} shows an example of the Fourier diffusion model using only 16 time steps for the reverse process. Notice the improvement in image quality for the Fourier diffusion model reverse process at $t=0$ in Figure \ref{fig:process_fourier_16} relative to the Fourier diffusion model reverse process  at $t=0$ in Figure \ref{fig:process_scalar_16}. The qualitative improvement in image quality for these two cases shows a convincing visual example of improved image quality for Fourier diffusion models when using a lower number of time steps and merits further quantitative image quality analysis. 

Figure \ref{fig:image_quality_metrics} shows the mean squared error, mean squared bias, and mean variance for scalar diffusion models and Fourier diffusion models. Here, the mean refers to spatial average over the images. The line plot represents the sample mean for the population of validation images and the shaded region represents one standard deviation over the population. From these plots, we conclude that Fourier diffusion models out-perform scalar diffusion models overall. All three metrics show improved performance for the Fourier diffusion models. In particular, we note the improved performance at a low number of time steps. Fourier diffusion models with only 8 time steps achieve similar mean squared error to scalar diffusion models using 128 or even 1024 time steps. The next section provides explanations and conclusions for these results.


\vspace{-6mm}

\section{Conclusion}

\vspace{-2mm}

The results of the experiments in the previous section show that Fourier diffusion models achieve higher performance than scalar diffusion models across multiple image quality metrics and number of time steps. The improved performance may be related to the greater apparent similarity between the initial images at $t=0$ and final images at $T$ for Fourier diffusion models relative to scalar diffusion models. It follows that the reverse process updates for the Fourier diffusion model are smaller than those of the scalar diffusion model, which may result in improved performance for a neural network with a fixed number of parameters. Intuitively, some denoising problems are harder than others and harder denoising problems require more computational power. The neural network used for the scalar diffusion model reverse updates must dedicate some of its computational power to inverting the imagined artificial process of the image signal fading to zero; whereas the Fourier diffusion model reverse updates are completely dedicated to moving the measured image distribution towards the true image distribution. Another possible explanation is the similarity between the LSI systems of the Fourier diffusion model and the convolutional layers of the neural network. It is possible that convolutional neural networks are better suited to model local sharpening and denoising operations of the Fourier diffusion model reverse updates, as opposed to the image-wide effects in the scalar diffusion models. 

While this work was originally motivated by the goal of controlling MTF and NPS in the forward process, we note that the derivations have not relied on any special properties of circulant matrices.  Therefore, we believe it should be possible to train score-based generative machine learning models defined by any Gaussian stochastic process composed of linear systems and additive Gaussian noise without specifying shift invariant systems or stationary noise. So far, we have only tested the machine learning implementation with Fourier diffusion models. In future work, we hope to explore new applications of the more general model.

Our final conclusion is that Fourier diffusion models have the potential to improve performance for conditional image generation relative to conventional scalar diffusion models. Fourier diffusion models can apply to medical imaging systems that are approximately shift invariant with stationary Gaussian noise. For the low-radiation-dose CT image restoration example, these improvements have the potential to improve image quality, diagnostic accuracy and precision, and patient health outcomes while keeping radiation dose at a suitable level for patient screening applications. We look forward to exploring new medical imaging applications of Fourier diffusion models in the future.








% \begin{figure}
%     \centering
% \includegraphics[width=0.9\textwidth]{figures/discrete_time_root_mean_squared_error.png}
%     \caption{Mean squared error vs number of time steps for the Fourier diffusion model and the scalar diffusion model. }
%     \label{fig:mean_squared_error}
% \end{figure}

% \begin{figure}
%     \centering
% \includegraphics[width=0.9\textwidth]{figures/discrete_time_root_mean_squared_bias.png}
%     \caption{Mean squared bias vs number of time steps for the Fourier diffusion model and the scalar diffusion model. }
%     \label{fig:mean_squared_bias}
% \end{figure}

% \begin{figure}
%     \centering
% \includegraphics[width=0.9\textwidth]{figures/discrete_time_root_mean_variance.png}
%     \caption{Mean squared bias vs number of time steps for the Fourier diffusion model and the scalar diffusion model. }
%     \label{fig:mean_variance}
% \end{figure}



\begin{figure}
    \centering
\includegraphics[trim={5mm 0mm 15mm 5mm},clip,width=0.32\textwidth]{figures/discrete_time_root_mean_squared_error.png}
\includegraphics[trim={3mm 0mm 15mm 5mm},clip,width=0.32\textwidth]{figures/discrete_time_root_mean_squared_bias.png}
\includegraphics[trim={3mm 0mm 15mm 5mm},clip,width=0.32\textwidth]{figures/discrete_time_root_mean_variance.png}
    \caption{Mean squared bias vs number of time steps for the Fourier diffusion model and the scalar diffusion model. The shaded region shows one standard deviation of the metric over the population of validation images. }
    \label{fig:image_quality_metrics}
\end{figure}







% \subsubsection{Algorithm for DDPM Training}

% \begin{algorithm}
%     \begin{algorithmic}
%     \State initialize the DDPM
%     \State initialize the optimizer
%     \State $n_\text{epoch} \gets 0$
%     \While{$n_\text{epoch} < N_{\text{epoch}}$}
%         \State $n_\text{batch} \gets 0$
%         \While{$n_\text{batch} < N_{\text{batch}}$}
%             \State $n_\text{image} \gets 0$
%             \State $\text{loss} \gets 0$
%             \While{$n_\text{image} < N_\text{image}$}
%                 \State $n \gets $  uniform random time between 0 and $N-1$
%                 \State $\mathbf{x}^{(0)} \gets $  random patient from training dataset
%                 \State $\boldsymbol{\alpha}^{(n)}, \boldsymbol{\alpha}^{(n+1)}\gets $  compute MTF coefficients
%                 \State $\boldsymbol{\beta}^{(n)}, \boldsymbol{\beta}^{(n+1)}\gets $  compute NPS coefficients
%                 \State $\mathbf{H}^{(n)}, \mathbf{H}^{(n+1)} \gets $ compute MTF using \eqref{eq:MTF_coefficients}
%                 \State $\boldsymbol{\Sigma}^{(n)}, \boldsymbol{\Sigma}^{(n+1)} \gets $ compute NPS using \eqref{eq:NPS_coefficients}
%                 \State $\mathbf{x}^{(n+1)} \gets \mathbf{H}^{(n+1)} \mathbf{x}^{(0)} +  \boldsymbol{\Sigma}^{1/2 \hspace{0.5mm}[n+1)} \mathbf{z} \enspace , \quad \mathbf{z}\sim\mathcal{N}(\mathbf{z}; \mathbf{0}, \mathbf{I})$
%                 \State $ \mathbf{H}^{(n)} \gets $ compute the LSI system using \eqref{eq:LSI_in_terms_of_MTF}
%                 \State $ \boldsymbol{\Sigma}_{\boldsymbol{\nu}}^{(n)} \gets $ compute the forward step noise covariance using \eqref{eq:noise_in_terms_of_NPS}
%                 \State $\boldsymbol{\Sigma}_\Delta^{(n)} \gets $ compute the reverse step noise covariance using \eqref{eq:Sigma_Delta}
%                 \State $\boldsymbol{\Sigma}^{(n)}_\text{Post.} \gets $ compute the posterior covariance using \eqref{eq:Sigma_posterior}
%                 \State $\boldsymbol{\mu}^{(n)}_\text{Post.} \gets $ compute the posterior mean using \eqref{eq:mu_posterior}
%                 \State $\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{(n)}(\mathbf{x}^{(n+1)}) , \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{(n)}(\mathbf{x}^{(n+1)}) \gets $  run the DDPM with inputs $\mathbf{x}^{(n+1)}$, $n$
%                 \State $\text{loss} \mathrel{+}= D_{KL}\Big( \text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  \hspace{-2mm},\mathbf{x}^{[0]}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  )\Big)$ using \eqref{eq:KL_divergence} or \eqref{eq:KL_divergence_simplified}
%                 \State $n_\text{image} \mathrel{+}= 1$
%             \EndWhile
%             \State loss.backward()   \hspace{5mm} \# compute gradient with respect to DDPM parameters 
%             \State optimizer.step()  \hspace{5mm} \# apply an optimization step
%             \State $n_\text{batch} \mathrel{+}= 1$
%         \EndWhile
%         \State $n_\text{epoch} \mathrel{+}= 1$
%     \EndWhile
%     \end{algorithmic}
% \caption{DDPM Training Algorithm with MTF and NPS Control}\label{alg:ddpm_training}
% \end{algorithm}


% \begin{algorithm}
%     \begin{algorithmic}
%     \Require $n \geq 0$
%     \Ensure $y = x^n$
%     \State $y \gets 1$
%     \State $X \gets x$
%     \State $N \gets n$
%     \While{$N \neq 0$}
%     \If{$N$ is even}
%         \State $X \gets X \times X$
%         \State $N \gets \frac{N}{2}$  \Comment{This is a comment}
%     \ElsIf{$N$ is odd}
%         \State $y \gets y \times X$
%         \State $N \gets N - 1$
%     \EndIf
%     \EndWhile
%     \end{algorithmic}
% \caption{Example}\label{alg:cap}
% \end{algorithm}






% \subsection{Application 1: Harmonizing Images from Multiple Systems}

% \subsection{Application 2: Task-Driven Image Quality Optimization}


% \section{Results}

% \subsection{Application 1: Harmonizing Images from Multiple Systems}

% \subsection{Application 2: Task-Driven Image Quality Optimization}



% \section{Conclusion}




\bibliography{main}
\bibliographystyle{spiejour}


% \section*{Appendix A}


% \begin{gather}
%     \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) = \log \hspace{-1mm}\int \hspace{-1mm} \ldots \hspace{-1mm} \int \hspace{-1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)},\mathbf{x}^{(1)} \hspace{-2mm} \ldots \mathbf{x}^{(N)} )  \mathbf{dx}^{(1)} \hspace{-1mm} \ldots\mathbf{dx}^{(N)} 
% \end{gather} 

% \noindent We can maintain equality by multiplying and dividing by the input-conditioned true process:

% \begin{gather}
%      \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) = \log \hspace{-1mm}\int \hspace{-1mm} \ldots \hspace{-1mm} \int \hspace{-1mm} \text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)}) \frac{\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)},\mathbf{x}^{(1)} \hspace{-2mm} \ldots \mathbf{x}^{(N)}  )}{\text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)})}  \mathbf{dx}^{(1)} \hspace{-2mm} \ldots\mathbf{dx}^{(N)}.
% \end{gather} 

% \noindent Then, we can apply Jensen's inequality to establish the evidence lower bound:

% \begin{gather}
%      \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) \geq \hspace{-1mm}\int \hspace{-1mm} \ldots \hspace{-1mm} \int \hspace{-1mm} \text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)}) \log \frac{\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)},\mathbf{x}^{(1)} \hspace{-2mm} \ldots \mathbf{x}^{(N)} )}{\text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)})}  \mathbf{dx}^{(1)} \hspace{-2mm} \ldots\mathbf{dx}^{(N)}.
% \end{gather} 

% \noindent Next, we can substitute $\text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)}) = \text{p}(\mathbf{x}^{(N)}|\mathbf{x}^{(0)})\prod_{n=0}^{N-1} \text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  ,\mathbf{x}^{(0)})$ and \\ $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)} ) = \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(N)})\prod_{n=0}^{N-1} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)} )$. We assume $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(N)})$ is constant with respect to $\boldsymbol{\theta}$ so we substitute the constants $c_2$ and $c_3$ in the equations below:

% \begin{gather}
%      \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) \geq \hspace{-2mm}\int \hspace{-2mm} \ldots \hspace{-2mm} \int \hspace{-1mm} \text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)}) \log c_2 
%      \prod_{n=0}^{N-1} \frac{\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)} )}{\text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  ,\mathbf{x}^{(0)})}  \mathbf{dx}^{(1)} \hspace{-2mm} \ldots\mathbf{dx}^{(N)} \\
%      \hspace{-5mm}\log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) \geq \hspace{-1mm}\int \hspace{-2mm} \ldots \hspace{-2mm} \int \hspace{-1mm} \text{p}(\mathbf{x}^{(0)},\mathbf{x}^{(1)}\hspace{-2mm}\ldots \mathbf{x}^{(N)}  |\mathbf{x}^{(0)}) \sum_{n=0}^{N-1} \log  \frac{\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)} )}{\text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  ,\mathbf{x}^{(0)})}  \mathbf{dx}^{(1)} \hspace{-2mm} \ldots\mathbf{dx}^{(N)}  \hspace{-1mm} + \hspace{-1mm} c_3\\
%      \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) \geq \sum_{n=0}^{N-1} \hspace{-1mm}\int \hspace{-1mm} \int \hspace{-1mm} \text{p}(\mathbf{x}^{(n)},\mathbf{x}^{(n+1)}  |\mathbf{x}^{(0)}) \log  \frac{\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)} )}{\text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  ,\mathbf{x}^{(0)})}  \mathbf{dx}^{(n)}\mathbf{dx}^{(n+1)} \hspace{-1mm} + \hspace{-1mm} c_3\\
%      \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(0)}) \geq \sum_{n=0}^{N-1} D_{KL}\Big( \text{p}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)}  ,\mathbf{x}^{(0)}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{(n)}| \mathbf{x}^{(n+1)})\Big) \hspace{-1mm} + \hspace{-1mm} c_3
% \end{gather}

% \section*{Appendix B}

% The loss function in \eqref{eq:ddpm_training} indicates the DDPM is trained to approximate the input-conditioned posterior distribution, $\text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)})$.  Applying Bayes rule to this posterior distribution yields

% \begin{equation}
%     \text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}) = \frac{\text{p}(\mathbf{x}^{(n+1)} | \mathbf{x}^{(n)}) \text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(0)})} { \text{p}(\mathbf{x}^{(n+1)} | \mathbf{x}^{(0)})} .
%     \label{eq:bayes_rule}
% \end{equation}

% \noindent Here, we have also used the conditional independence identity, $\text{p}(\mathbf{x}^{(n+1)} | \mathbf{x}^{(n)}, \mathbf{x}^{(0)}) = \text{p}(\mathbf{x}^{(n+1)} | \mathbf{x}^{(n)})$. Taking the negative logarithm and substituting  \eqref{eq:forward_step} and \eqref{eq:effective_MTF_NPS} yields

% \begin{gather}
%     -\log\text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}) = -\log \text{p}(\mathbf{x}^{(n+1)} | \mathbf{x}^{(n)}) - \log \text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(0)}) + c_0 \\
%     -\log\text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}) = \frac{1}{2}(\mathbf{x}^{(n+1)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(n)})^T \boldsymbol{\Sigma}_{\nu}^{-1 \hspace{0.5mm} (n)}(\mathbf{x}^{(n+1)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(n)})  \nonumber \\ 
%     \enspace \hspace{52mm} +\frac{1}{2}(\mathbf{x}^{(n)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)})^T \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)}(\mathbf{x}^{(n)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)}) +  c_1  \\
%     -\log\text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}) = \frac{1}{2}(\mathbf{x}^{(n)} - \mathbf{H}^{-1 \hspace{0.5mm} (n)} \mathbf{x}^{(n+1)})^T\mathbf{H}^{(n)} \boldsymbol{\Sigma}_{\nu}^{-1 \hspace{0.5mm} (n)}\mathbf{H}^{(n)}(\mathbf{x}^{(n)} - \mathbf{H}^{-1 \hspace{0.5mm} (n)} \mathbf{x}^{(n+1)})  \nonumber \\ 
%     \enspace \hspace{52mm} +\frac{1}{2}(\mathbf{x}^{(n)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)})^T \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)}(\mathbf{x}^{(n)} - \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)}) +  c_1
% \end{gather}

% \noindent Here, $c_0$ and $c_1$ are constants with respect to $\mathbf{x}^{(n)}$. With further algebraic manipulation, we can show that the input-conditioned posterior has the following Gaussian distribution:

% \begin{gather}
%     \text{p}(\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)})    = \mathcal{N}(\mathbf{x}^{(n)}; \boldsymbol{\mu}_{\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}} = \boldsymbol{\mu}_\text{Post.}^{(n)},\boldsymbol{\Sigma}_{\mathbf{x}^{(n)} | \mathbf{x}^{(n+1)}, \mathbf{x}^{(0)}} = \boldsymbol{\Sigma}_\text{Post.}^{(n)}) \label{eq:posterior} \\
%     \boldsymbol{\Sigma}_\Delta^{(n)}  \triangleq \mathbf{H}^{-1 \hspace{0.5mm}(n)} \boldsymbol{\Sigma}_{\boldsymbol{\nu}}^{(n)}\mathbf{H}^{-1 \hspace{0.5mm} (n)} =  \mathbf{H}^{-1 \hspace{0.5mm}(n)}\boldsymbol{\Sigma}^{(n+1)}\mathbf{H}^{-1 \hspace{0.5mm} (n)} - \boldsymbol{\Sigma}^{(n)}  \label{eq:Sigma_Delta}\\
%     \boldsymbol{\Sigma}_\text{Post.}^{(n)}  = 
%     [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n)} + \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)}]^{-1}   =  \boldsymbol{\Sigma}_\Delta^{(n)}  [\boldsymbol{\Sigma}_\Delta^{(n)}  + \boldsymbol{\Sigma}^{(n)}]^{-1} \boldsymbol{\Sigma}^{(n)} \label{eq:Sigma_posterior}\\ \nonumber
%     \boldsymbol{\mu}_\text{Post.}^{(n)}  = [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n)} \hspace{-2mm} + \hspace{-1mm} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)}]^{-1} \boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n)} \mathbf{H}^{-1 \hspace{0.5mm} (n)} \mathbf{x}^{(n+1)} \hspace{-1mm}+       [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n)} \hspace{-2mm}+\hspace{-1mm} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)}]^{-1} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n)} \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)} \\
%       = [\boldsymbol{\Sigma}_\Delta^{(n)} + \boldsymbol{\Sigma}^{ (n)}]^{-1}\Big[\boldsymbol{\Sigma}^{(n)}  \mathbf{H}^{-1 \hspace{0.5mm} (n)} \mathbf{x}^{(n+1)}  + \boldsymbol{\Sigma}_\Delta^{(n)}  \mathbf{H}^{(n)} \hspace{1mm} \mathbf{x}^{(0)} \Big]\label{eq:mu_posterior}
% \end{gather}


\newpage

\section*{Appendix A}


% The continuous-time stochastic process defined in \eqref{eq:x_t} is 
% \begin{equation}
% \mathbf{x}^{(t)} = \mathbf{H}^{(t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(t)}}^{\hspace{-3mm}  1/2} \boldsymbol{\epsilon}^{(t)}  
% \end{equation}

% \noindent Consider a discrete-time stochastic process, $\mathbf{x}^{[n]}$ generated by sampling $N+1$ time points on the interval $t \in (0,1)$ with time samples evenly spaced by $\Delta t = 1/N$. Note that $\mathbf{x}^{[n]}$ and $\mathbf{x}^{(t)}$ are distinct variables related by this sampling procedure. The formula for that discrete process is

% \begin{gather}
%     \mathbf{x}^{[n]} = \mathbf{H}^{[n]} \mathbf{x}^{[0]} + {\boldsymbol{\Sigma}^{[n]}}^{\hspace{-0mm}  1/2} \boldsymbol{\epsilon}^{[n]} \\
%     = \mathbf{x}^{(n \Delta t)} = \mathbf{H}^{(n \Delta t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(n \Delta t)}}^{\hspace{-0mm}  1/2} \boldsymbol{\epsilon}^{(n \Delta t)} 
% \end{gather}




% \noindent According to \eqref{eq:LSI_in_terms_of_MTF_} and \eqref{eq:noise_in_terms_of_NPS}, the forward update step for $\mathbf{x}^{[n+1]}$ in terms of $\mathbf{x}^{[n]}$ is defined by:

% \begin{gather}
%     \mathbf{x}^{[n + 1]} = \mathbf{H}^{[n + 1]} {\mathbf{H}^{[n]}}^{\hspace{-3mm}-1} \mathbf{x}^{[n]} + (\boldsymbol{\Sigma}^{[n+1]} -  {\mathbf{H}^{[n+1]}}^{\hspace{-0mm} 2} {\mathbf{H}^{[n]}}^{\hspace{-3mm}-2} \boldsymbol{\Sigma}^{[n]} )^{1/2} \boldsymbol{\eta}^{[n]}
%     \label{eq:x_n_plus_1_}
% \end{gather}

% \noindent where $\boldsymbol{\eta}^{[n]}$ is  zero-mean identity-covariance Gaussian noise and is independent of $\boldsymbol{\epsilon}^{[n]}$. Equivalently, we can rewrite this formula as samples of the continuous time process as follows

Consider a stochastic process defined by the following 

\begin{equation}
\mathbf{x}^{(t)} = \mathbf{H}^{(t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}  1/2} \boldsymbol{\epsilon}^{(t)} 
\label{eq:x_t_general}
\end{equation}

\noindent where $\mathbf{H}^{(t)}$ and $\boldsymbol{\Sigma}^{(t)}$ are time-dependent square matrices and $\boldsymbol{\epsilon}^{(t)}$ is a zero-mean identity-covariance Gaussian random process with independent non-overlapping time intervals. We assume $\mathbf{H}^{(0)} = \mathbf{I}$ and $\boldsymbol{\Sigma}^{(0)} = \mathbf{0}$, $\mathbf{H}^{(t)}$ is invertible, and $\boldsymbol{\Sigma}^{(t+\Delta t)}\geq \mathbf{H}^{(t+\Delta t)}{\mathbf{H}^{(t)}}^{-1}\boldsymbol{\Sigma}^{(t)}{{\mathbf{H}^T}^{(t)}}^{-1} {\mathbf{H}^T}^{(t+\Delta t)}$ for all elements. 


For the continuous forward stochastic process, $\mathbf{x}^{(t)}$ defined in  \eqref{eq:x_t}, we can write the update for a time step $\Delta t$ by combining \eqref{eq:discrete_forward_update_MTF_NPS} and \eqref{eq:sample_discrete} as follows:
\begin{gather}
    \mathbf{x}^{(t+\Delta t)} = \mathbf{H}^{(t + \Delta t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} + (\boldsymbol{\Sigma}^{(t + \Delta t)} -  {\mathbf{H}^{(t + \Delta t)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}
    \label{eq:x_t_plus_delta_t}
\end{gather}

\noindent where $\boldsymbol{\eta}^{(t)}$ is a zero-mean identity-covariance Gaussian  process. Subtracting $\mathbf{x}^{(t)}$ yields

\begin{gather}
    \mathbf{x}^{(t + \Delta t)} - \mathbf{x}^{(t)}  =  (\mathbf{H}^{(t + \Delta t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} - \mathbf{I}) \mathbf{x}^{(t)} + (\boldsymbol{\Sigma}^{(t + \Delta t)} -  {\mathbf{H}^{(t+\Delta t)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{-3mm}-2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}
    \label{eq:x_t_difference}
\end{gather}

\noindent The first term of \eqref{eq:x_t_difference} can be algebraically rearranged as follows:

\begin{gather}
    (\mathbf{H}^{(t + \Delta t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} - \mathbf{I}) \mathbf{x}^{(t)} \\
    (\mathbf{H}^{(t + \Delta t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} - \mathbf{H}^{(t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}) \mathbf{x}^{(t)} \\
    (\mathbf{H}^{(t + \Delta t)}  - \mathbf{H}^{(t)}) {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \\
    \frac{\mathbf{H}^{(t + \Delta t)}  - \mathbf{H}^{(t)}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \Delta t \label{eq:first_term}
\end{gather}

\noindent Taking the limit of \eqref{eq:first_term} as $\Delta t$ approaches zero yields

\begin{gather}
    \lim_{\Delta t \rightarrow 0} \frac{\mathbf{H}^{(t + \Delta t)}  - \mathbf{H}^{(t)}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \Delta t = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \text{dt}
\end{gather}

\noindent where $\mathbf{H^{'}}^{(t)} = \frac{\text{d}}{\text{dt}} \mathbf{H}^{(t)} $

The second term of \eqref{eq:x_t_difference} can also be algebraically rearranged as follows:

\begin{gather}
    (\boldsymbol{\Sigma}^{(t + \Delta t)} -  {\mathbf{H}^{(t+\Delta t)}}^{\hspace{-0mm} 2} {\mathbf{H}^{(t)}}^{\hspace{0mm}-2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}  \\
    (\boldsymbol{\Sigma}^{(t + \Delta t)} - ( {\mathbf{H}^{(t+\Delta t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1})^2 \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}  \\
    (\boldsymbol{\Sigma}^{(t + \Delta t)} - (\mathbf{I} +  {\mathbf{H}^{(t+\Delta t)}}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} - \mathbf{I})^{2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}  \\
    (\boldsymbol{\Sigma}^{(t + \Delta t)} - (\mathbf{I} +  {\mathbf{H}^{(t+\Delta t)}}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} -  {\mathbf{H}^{(t)}}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1})^{2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}  \\
    (\boldsymbol{\Sigma}^{(t + \Delta t)} - (\mathbf{I} +  ({\mathbf{H}^{(t+\Delta t)}} -  {\mathbf{H}^{(t)}}) {\mathbf{H}^{(t)}}^{\hspace{0mm}-1})^{2} \boldsymbol{\Sigma}^{(t)} )^{1/2} \boldsymbol{\eta}^{(t)}  \\
    (\boldsymbol{\Sigma}^{(t + \Delta t)} - (\mathbf{I} +  \frac{{\mathbf{H}^{(t+\Delta t)}} -  {\mathbf{H}^{(t)}}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \Delta t)^{2} \boldsymbol{\Sigma}^{(t)} )^{1/2} 
    \boldsymbol{\eta}^{(t)} \\
    (\frac{\boldsymbol{\Sigma}^{(t + \Delta t)} - (\mathbf{I} + 
    2\frac{\mathbf{H}^{(t+\Delta t)} -  {\mathbf{H}^{(t)}}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \Delta t + \mathcal{O}(\Delta t^2)) \boldsymbol{\Sigma}^{(t)}}{\Delta t} )^{1/2}
     \sqrt{\Delta t} \enspace \boldsymbol{\eta}^{(t)} \\
    (-  2 \frac{{\mathbf{H}^{(t+\Delta t)}} -  {\mathbf{H}^{(t)}}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \frac{\boldsymbol{\Sigma}^{(t + \Delta t)} - \boldsymbol{\Sigma}^{(t)}}{\Delta t}  - \frac{\mathcal{O}(\Delta t^2)}{\Delta t} \boldsymbol{\Sigma}^{(t)}  )^{1/2} \sqrt{\Delta t} \enspace \boldsymbol{\eta}^{(t)} \label{eq:second_term}
\end{gather}

\noindent where $\mathcal{O}(\Delta t^2)$ indicates second order and higher terms of the Taylor expansion. Note, we have made the approximation that $\frac{\mathbf{H}^{(t+\Delta t)} -  {\mathbf{H}^{(t)}}}{\Delta t}$ can be considered as a constant with respect to $\Delta t$ for the purposes of the Taylor expansion, which is valid for continuously differentiable functions of time in the limit as $\Delta t$ approaches zero. Taking the limit of \eqref{eq:second_term} as $\Delta t$ approaches zero yields

\begin{gather}
    \lim_{\Delta t \rightarrow 0} (-  2 \frac{{\mathbf{H}^{(t+\Delta t)}} -  {\mathbf{H}^{(t)}}}{\Delta t} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \frac{\boldsymbol{\Sigma}^{(t + \Delta t)} - \boldsymbol{\Sigma}^{(t)}}{\Delta t} + \frac{\mathcal{O}(\Delta t^2)}{\Delta t} \boldsymbol{\Sigma}^{(t)})^{1/2} \sqrt{\Delta t} \enspace \boldsymbol{\eta}^{(t)} \\
    (-  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \boldsymbol{\Sigma^{'}}^{(t)}  )^{1/2} \mathbf{dw}
\end{gather}

\noindent where $\boldsymbol{\Sigma^{'}}^{(t)} = \frac{\text{d}}{\text{dt}} \boldsymbol{\Sigma}$ and $\mathbf{dw}$ is infinitesimal white Gaussian noise with covariance, $\text{dt} \mathbf{I}$. Therefore, the limit of \eqref{eq:x_t_difference} as $\Delta t$ approaches zero is:

\begin{equation}
    \mathbf{dx} = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \text{dt} + (-  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \boldsymbol{\Sigma^{'}}^{(t)}  )^{1/2} \mathbf{dw}
\end{equation}





% \newpage

% \section*{Appendix B}

% This work was motivated by the goal of controlling spatial resolution and noise in the spatial frequency domain. However, we have not relied on any special properties of circulant matrices. Therefore, we can write a more general version that may be useful for some cases. Consider a forward stochastic process where update steps are defined by the linear system, $\mathbf{H}^{(t)}$ and additive Gaussian noise with covariance, $\boldsymbol{\Sigma}^{(t)}$ as defined below:

% \begin{gather}
% \mathbf{x}^{(t)} = \mathbf{H}^{(t)} \mathbf{x}^{(0)} + {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}  1/2} \boldsymbol{\epsilon}^{(t)}  .
% \label{eq:x_t_general}
% \end{gather}

% \noindent The corresponding forward stochastic differential equation is

% \begin{equation}
%     \mathbf{dx} = \mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} \text{dt} + (\boldsymbol{\Sigma^{'}}^{(t)}  -  2 {\mathbf{H^{'}}^{(t)}} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} )^{1/2} \mathbf{dw} , \label{eq:SDE_general}
% \end{equation}

% \noindent and the time-reversed stochastic differential equation is

% \begin{gather}
%      \mathbf{dx} = [\mathbf{H^{'}}^{(t)}{\mathbf{H}^{(t)}}^{\hspace{0mm}-1} \mathbf{x}^{(t)} - (-  2 {\mathbf{H^{'}}}^{(t)} {{\mathbf{H}}^{(t)}}^{\hspace{0mm}-1}  
%      \boldsymbol{\Sigma}^{(t)} + \boldsymbol{\Sigma^{'}}^{(t)} )  \nabla \log{\text{p} (\mathbf{x}^{(t)}|\mathbf{y})}] \text{dt} \nonumber \\
%      \hspace{70mm} + (-  2 {\mathbf{H^{'}}}^{(t)} {\mathbf{H}^{(t)}}^{\hspace{0mm}-1}  \boldsymbol{\Sigma}^{(t)} + \boldsymbol{\Sigma^{'}}^{(t)}  )^{1/2} \mathbf{dw}.
% \end{gather}

% \noindent For this general case, the score-matching loss function is

% \begin{equation}
% \underset{\mathbf{x}^{(0)}, t}{\mathbb{E}}[(\boldsymbol{\hat{\epsilon}}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \boldsymbol{\epsilon}^{(t)})^T {\boldsymbol{\Sigma}^{(t)}}^{\hspace{0mm}-1} (\boldsymbol{\hat{\epsilon}}_{\boldsymbol{\theta}}(\mathbf{x}^{(t)}, \mathbf{y}, t) - \boldsymbol{\epsilon}^{(t)}) ]
% \end{equation}



% For the experiments in this article, we focus on the forward process in \eqref{eq:x_t} and score-matching loss function in \eqref{eq:score_matching_loss} using circulant matrices to train measurement-conditioned Fourier diffusion models for medical image restoration. In the future, we are interested in exploring more applications of the more general equations above. 












% \section*{Appendix C}


% Stochastic diffusion models are designed to sample new images from the distribution of the training data, $\text{p}(\mathbf{x}^{[0]})$. The approach is to fit a probabilistic model, $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[0]},\mathbf{x}^{[1]},\ldots,\mathbf{x}^{[N]})$, to the joint distribution, $\text{p}(\mathbf{x}^{[0]},\mathbf{x}^{[1]},\ldots,\mathbf{x}^{[N]})$, by optimizing the model parameters, $\boldsymbol{\theta}$. Specifically, the model approximates the posterior time step, $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]} )$.  Since the noise at each time step is independent, the trained approximation of the full reverse process can be written in terms of these individual reverse updates as follows: 

% \begin{gather}
% \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[0]},\mathbf{x}^{[1]}\hspace{-2mm}\ldots \mathbf{x}^{[N]} ) = \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[N]})\prod_{n=0}^{N-1} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]} ) \enspace .
% \end{gather}


% We assume that $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[N]})$ is well-defined and constant with respect to $\boldsymbol{\theta}$. That is, we assume there is a known way to generate a sample image from the final time step, $\mathbf{x}^{[N]}$, to initialize the reverse process. Examples of known $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[N]})$ include the case where the forward process ends in zero-mean Gaussian noise (for unconditional image generation) or the case where the forward process ends in the same distribution as the measurements of a medical imaging system (for conditional image generation).

% % \subsubsection{Loss Function for DDPM Training: The Evidence Lower Bound  }

% To train the stochastic diffusion model to generate new samples from the training data distribution, we would like to maximize $\log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[0]})$. In Appendix A, we derive the evidence lower bound (ELBo) following the same steps described in \cite{ho2020denoising}.  The ELBo is defined as

% \begin{equation}
%     \log \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[0]}) \geq \sum_{n=0}^{N-1} D_{KL}\Big( \text{p}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  ,\mathbf{x}^{[0]}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]})\Big) \hspace{-1mm} + \hspace{-1mm} c_3
%     \label{eq:elbo}
% \end{equation}


% \noindent where $D_{KL}\Big(\cdot\Big)$ represents the Kullback-Leibler divergence between two probability distributions. We can use can use the right-hand side of \eqref{eq:elbo} as a surrogate loss function for optimization transfer. The ELBo is defined as Therefore, the training loss is defined as the sample mean of the evidence lower bound over the distribution of ground-truth images $\mathbf{x}^{[0]}$ and time steps, $n$, as shown below:

% \begin{equation}
%     \boldsymbol{\hat{\theta}}  = \underset{\boldsymbol{\theta}}{\text{argmin}} \underset{\mathbf{x}^{[0]}, n}{\mathbb{E}}\Big[D_{KL}\Big( \text{p}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  \hspace{-2mm},\mathbf{x}^{[0]}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  )\Big)\Big] .
%     \label{eq:ddpm_training}
% \end{equation}

% During training, we have access to the full forward process including $\mathbf{x}^{[n]}$ and $\mathbf{x}^{[n+1]}$ for all values of $n$; however, we need to define the true input-conditioned posterior, $\text{p}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  \hspace{-2mm},\mathbf{x}^{[0]})$, to evaluate the ELBo loss function. In Appendix B, we derive the following formulae:

% \begin{gather}
%     \text{p}(\mathbf{x}^{[n]} | \mathbf{x}^{[n+1]}, \mathbf{x}^{[0]})    = \mathcal{N}(\mathbf{x}^{[n]}; \boldsymbol{\mu}_{\mathbf{x}^{[n]} | \mathbf{x}^{[n+1]}, \mathbf{x}^{[0]}} = \boldsymbol{\mu}_\text{Post.}^{[n]},\boldsymbol{\Sigma}_{\mathbf{x}^{[n]} | \mathbf{x}^{[n+1]}, \mathbf{x}^{[0]}} = \boldsymbol{\Sigma}_\text{Post.}^{[n]}) \label{eq:posterior} \\
%     \boldsymbol{\Sigma}_\Delta^{[n]}  \triangleq \mathbf{H}^{-1 \hspace{0.5mm}(n]} \boldsymbol{\Sigma}_{\boldsymbol{\nu}}^{[n]}\mathbf{H}^{-1 \hspace{0.5mm} (n]} =  \mathbf{H}^{-1 \hspace{0.5mm}(n]}\boldsymbol{\Sigma}^{[n+1]}\mathbf{H}^{-1 \hspace{0.5mm} (n]} - \boldsymbol{\Sigma}^{[n]}  \label{eq:Sigma_Delta}\\
%     \boldsymbol{\Sigma}_\text{Post.}^{[n]}  = 
%     [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n]} + \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]}]^{-1}   =  \boldsymbol{\Sigma}_\Delta^{[n]}  [\boldsymbol{\Sigma}_\Delta^{[n]}  + \boldsymbol{\Sigma}^{[n]}]^{-1} \boldsymbol{\Sigma}^{[n]} \label{eq:Sigma_posterior}\\ 
%     \boldsymbol{\mu}_\text{Post.}^{[n]}  = [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n]} \hspace{-2mm} + \hspace{-1mm} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]}]^{-1} \boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n]} \mathbf{H}^{-1 \hspace{0.5mm} (n]} \mathbf{x}^{[n+1]} \hspace{-1mm}+       [\boldsymbol{\Sigma}_\Delta^{-1 \hspace{0.5mm} (n]} \hspace{-2mm}+\hspace{-1mm} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]}]^{-1} \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]} \mathbf{H}^{[n]} \hspace{1mm} \mathbf{x}^{[0]} \\
%       = [\boldsymbol{\Sigma}_\Delta^{[n]} + \boldsymbol{\Sigma}^{ (n]}]^{-1}\Big[\boldsymbol{\Sigma}^{[n]}  \mathbf{H}^{-1 \hspace{0.5mm} (n]} \mathbf{x}^{[n+1]}  + \boldsymbol{\Sigma}_\Delta^{[n]}  \mathbf{H}^{[n]} \hspace{1mm} \mathbf{x}^{[0]} \Big]\label{eq:mu_posterior}
% \end{gather}

% The posterior mean,  $\boldsymbol{\mu}^{[n]}_\text{Post.}$, defined in \eqref{eq:mu_posterior} and covariance, $\boldsymbol{\Sigma}^{[n]}_\text{Post.}$, defined in \eqref{eq:Sigma_posterior}, can be computed in terms of the current image, $\mathbf{x}^{[n+1]}$, the ground-truth image, $\mathbf{x}^{[0]}$, and the time-dependent MTF and NPS. 

% Since $\text{p}(\mathbf{x}^{[n]} | \mathbf{x}^{[n+1]}, \mathbf{x}^{[0]})$ is Gaussian, it is reasonable to model $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]})$ as Gaussian parameterized by the time-dependent mean estimator, $\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]})$, and time-dependent covariance estimator $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} )$. The parameters, $\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}$ and $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{[n]}$ are the outputs in general of the DDPM and the argument $\mathbf{x}^{[n+1]}$, and $n$ are the inputs to the DDPM. In this case, the KL divergence for a given time step is given by:

% % http://orion.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf

% \begin{gather}
%    \hspace{-10mm} D_{KL}\Big( \text{p}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  \hspace{-2mm},\mathbf{x}^{[0]}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]})\Big) = \nonumber \\
%    \frac{1}{2}\Big[\log |\boldsymbol{\Sigma}^{[n]}_\text{Post.}| - \log |\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]})|+ \text{tr}\Big(\boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]}_\text{Post.} \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]}) - \mathbf{I}\Big)  \nonumber \\ (\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]}) - \boldsymbol{\mu}^{[n]}_\text{Post.})^T \boldsymbol{\Sigma}^{-1}_\text{Post.} (\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} )-\boldsymbol{\mu}^{[n]}_\text{Post.})   \Big]. \label{eq:KL_divergence}
% \end{gather}

% \noindent We will focus on the special case where we assume $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} ) = \boldsymbol{\Sigma}^{[n]}_\text{Post.}$, so the only DDPM output is $\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]})$. In this case, the KL divergence simplifies to:

% \begin{gather}
%    D_{KL}\Big( \text{p}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  \hspace{-2mm},\mathbf{x}^{[0]}) \hspace{1mm} | \hspace{1mm} \hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]} )\Big) =  \nonumber \\ \frac{1}{2} (\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]}) - \boldsymbol{\mu}^{[n]}_\text{Post.})^T \boldsymbol{\Sigma}^{-1 \hspace{0.5mm} (n]}_\text{Post.} (\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} )-\boldsymbol{\mu}^{[n]}_\text{Post.}) . \label{eq:KL_divergence_simplified}
% \end{gather}

% After the model is trained, we can use, $\hat{\text{p}}_{\boldsymbol{\theta}}(\mathbf{x}^{[n]}| \mathbf{x}^{[n+1]}  )$, to run the approximate time-reversed stochastic process step-by-step to generate images as shown in Figure \ref{fig:network_diagram}.

% Following the form of \eqref{eq:mu_posterior} and substituting $\mathbf{x}^{[0]} \approx {\mathbf{H}^{[n]}}^{\hspace{-3mm}-1}[\mathbf{x}^{[n]} - {\boldsymbol{\Sigma}^{[n]}}^{\hspace{-3mm}1/2} \boldsymbol{\hat{\epsilon}_\theta}^{[n]}]$, we can parameterize $\hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} )$ as follows

% \begin{gather}
%     \hat{\boldsymbol{\mu}}_{\boldsymbol{\theta}}^{[n]}(\mathbf{x}^{[n+1]} )  =  [\boldsymbol{\Sigma}_\Delta^{[n]} + \boldsymbol{\Sigma}^{ [n]}]^{-1}\Big[\boldsymbol{\Sigma}^{[n]}  \mathbf{H}^{-1 \hspace{0.5mm} [n]} \mathbf{x}^{[n+1]}  + \boldsymbol{\Sigma}_\Delta^{[n]}    [\mathbf{x}^{[n]} - {\boldsymbol{\Sigma}^{[n]}}^{\hspace{-3mm}1/2} \boldsymbol{\hat{\epsilon}_\theta}^{[n]}] \Big]
% \end{gather}


















\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%